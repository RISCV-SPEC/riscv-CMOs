== Introduction (Ignore)

_Cache management operation_ (_CMO_) instructions perform operations on caches
in the memory hierarchy. These instructions may be classified in a number of
ways as follows:

* A _management_ instruction manipulates the contents of caches

* A _zero_ instruction writes zeros to a range of memory locations and may
  allocate a cache block in a cache accessed by a hart

* A _prefetch_ instruction may allocate a cache block in a cache accessed by a
  hart in anticipation of 




In general, a CMO instruction initiates an operation on a set of caches based 
on instruction type, CSR state, physical memory attributes, and other 
architectural state.
The CSR state determines whether a particular CMO instruction is executed or traps and, in
some cases, modifies the behavior of the instruction.
A CMO instruction specifies an effective address, which may be translated by 
various translation mechanisms into a physical address.
A hart may then perform a subsequent memory access with that physical address 
in order to operate on various caches throughout a system.


== Background (Only Read This)

***

*START READING HERE*

***

As specified in the RISC-V base and privileged architectures, memory is
organized as an array of bytes, with a given physical address identifying a
particular memory location. An _observer_ of a memory location is a hart or an
I/O device that can load from or store to that memory location; a given observer
may _not_ be able to access all memory locations in the system.

****

_Loads and stores are operations performed by an observer, while reads and
writes are operations performed on a memory location. These operations may be
decoupled by caches, described below. For example, a load may be serviced by a
cache without performing a read of memory, or a write may be serviced by a cache
by first performing a read of memory._

****

When performing loads and stores, an observer may access any number of _caches_
that may provide the requested data instead of the underlying memory locations.
A cache buffers copies of data organized into _cache blocks_, which consist of
naturally aligned power-of-two (_NAPOT_) sets of contiguous bytes. Each cache
block is tagged with a physical address that identifies the corresponding memory
locations. The organization of each cache and the size of a cache block are both
_implementation-defined_.

A cache may be _private_, in which case the cache is accessed by a single
observer, or _shared_, in which case cache is accessed by more than one
observer. Multiple cache blocks for the same memory locations may be present in
the system simultaneously, introducing multiple copies of data, and a system may
implement mechanisms to keep the data in some or all of those copies coherent.

For a given memory location, a _set of coherent observers_ consists of the set
of observers for which all of the following are true:

* Stores from all observers in the set appear to be serialized with respect to
  each other

* Stores from all observers in the set eventually appear to all other observers
  in the set

* A load from an observer in the set returns the data values from a store from 
  an observer in the set (or the initial data values in memory)

Coherent observers _must_ access a given memory location with the same physical
address and the same memory attributes, particularly coherence and cacheability.

****

_Effectively, the loads and stores performed by the set of coherent observers
are subject to one of the memory order models defined by the ISA._

****

An observer who is a member of a set of coherent observers is said to be
_coherent_ with respect to the other observers in the set. On the other hand, an
observer who is _not_ a member is said to be _non-coherent_ with respect to the
observers in the set.

For a given cache block, the caches accessed by the coherent observers are kept
coherent by an _implementation_defined_ mechanism. Such a _coherent cache_ may
read the cache block at any time from another coherent cache or from the
underlying memory locations. Similarly, a coherent cache may write the cache
block at any time to another coherent cache. In addition, a coherent cache may
write the cache block at any time to the underlying memory locations, provided
that a coherent observer performed a store to the cache block since the previous
such write. In this case, in the absence of an invalidate operation performed by
a coherent observer, at least one coherent cache _must_ write the cache block to
the underlying memory locations; otherwise, no coherent cache may write the
cache block to the underlying memory locations.

****

_The above restrictions ensure that a "clean" copy cannot be written back into
memory._

****

Cache block management operations enable software running on a set of coherent
observers to communicate with a set of non-coherent observers:

* An _invalidate operation_ makes stores from a set of non-coherent observers
  appear to the set of coherent observers by removing all copies of a cache
  block from the coherent caches

* A _clean operation_ makes stores from the set of coherent observers appear to
  a set of non-coherent observers by writing a copy of a cache block to the
  underlying memory locations (or to a cache shared by both sets), provided a
  coherent observer stored to the cache block since the previous such write

* A _flush operation_ atomically performs a clean operation followed by an
  invalidate operation

*_FIXME:_* There is some question whether the two sub-operations in a flush
operation must be atomic.

Cache block zero operations perform a series of store byte operations where the
data are zero. An implementation may or may not update the entire cache block
atomically.

Cache block prefetch operations are performance hints to the coherent caches to
guide the placement of cache blocks. As hints, these operations may or may not
cause cache blocks to be transferred to a particular cache.

=== Specifying Caches

Replacement for PoC:

* Point of 

* Shared Access Point (SAP)

* Common Access Point (CAP)

* point of common access (PCA)

* Point of Shared Access

* Joint, 


The set of coherent observers is a function of the physical address and the
memory attributes of the access. As a result, the whatever point/level is
determined by the same characteristics.

For example, the set of coherent observers for a non-coherent attribute is only
the executing hart.

CMOs ignore cacheability so PCA must be explicit vs. implicit above.

***

*STOP READING HERE*

***

== Don't read beyond here



=== System Topology (Stale)

A memory access from a CMO instruction proceeds along _memory access path_ (or 
_path_ for short) from a given system agent toward a given memory location.
A path is determined primarily by the following characteristics:

* The physical address of the memory access
* The memory attributes associated with the memory access

The physical address identifies the memory location being accessed and is a 
function of the effective address specified by a CMO instruction and any 
enabled translation mechanisms.
In addition, the memory attributes for a memory access may be specified by 
either architectural or _implementation-defined_ mechanisms.
Other factors, such as type of operation, may also influence the path.

****
_The memory attributes that typically affect a path are related to cacheability_
_and coherence; however, other memory attributes may affect a path._

_From the same system agent, paths for memory accesses with the same memory_
_attributes to different memory locations may be different._
_Likewise, paths for memory accesses with different memory attributes to the_
_same memory location may be different._
****

Paths from different system agents to the same memory location converge at a 
_point of convergence_ (or _PoC_), and from a given PoC, the paths that have 
converged do not diverge.
In addition, the memory accesses on those paths are ordered, and remain 
ordered, with respect to each other from a PoC until the memory accesses can be 
completed.
A PoC is _not_ required to order memory accesses to different memory locations.
Once an order has been established, those memory accesses are considered to be 
_access ordered_ and cannot be reordered within the system.

****
_This ordering definition is necessary to implement cache coherence protocols_
_and forms the basis for the memory ordering model below._
_Effectively, a PoC establishes a coherence order for a given memory location_
_with respect to a given set of agents._
****

For every memory location in a system, the _point of convergence of memory_, or 
_PoC-memory_, is the PoC where all paths for a given memory location converge, 
independent of all other characteristics that define a path.
At the PoC-memory, all accesses to a memory location have been access ordered, 
and the CMO instructions defined in this extension are guaranteed to operate on 
a path up to the PoC-memory.

*_FIXME:_* Define other standard PoCs?

****
_This extension does not prohibit system agents from bypassing the PoC-memory_
_to access a memory location, nor does the extension prohibit memory caches_
_beyond the PoC-memory._
_However, in such a system, software cannot expect the currently defined cache_
_operations to have the desired effects with respect to those system agents or_
_caches._

_Additional system topology beyond the PoC-memory may be specified in future_
_extensions._
_For example, additional points of convergence may be defined to manage memory_
_caches, or various points of persistence may be defined to support different_
_classes of storage._
****

A system may define additional custom PoCs before the PoC-memory, and when such 
a PoC is specified in a CMO instruction, the instruction _must_ operate on a 
given path up to the custom PoC and may operate on the path up to the 
PoC-memory.
A CMO instruction is _not_ required, however, to operate on the path beyond a 
custom PoC.

****
_The above definition allows an implementation to perform all operations to_
_custom PoCs before the PoC-memory as if such operations were performed to the_
_PoC-memory._
****

While traversing a given path, a memory access from a CMO instruction operates
on the caches up to the specified PoC.
Between a system agent and the first PoC on the path, the memory access
operates on private caches, and between subsequent PoCs, the memory access
operates on shared caches.
There is no requirement, however, for any caches to be present either between a
system agent and the first PoC or between subsequent PoCs.
Caches on the path are accessed _directly_ by the memory access.
Additional caches on the paths that converge at a given PoC may be accessed
_indirectly_ depending on the memory attributes associated with a memory access
and any _implementation-defined_ cache coherence mechanisms.

Systems may implement hardware cache coherence mechanisms to ensure that the 
copies in a set of caches remain _coherent_ with respect to each other, i.e. 
the copies in the set of caches appear to have the same data values, regardless 
of which cache in the set is accessed.
The set of caches on which hardware can maintain this property corresponds to a 
_hardware coherence domain_ (or _domain_ for short), which may consist of any 
number of caches, including an individual cache.
Only a subset of the caches in a domain may be accessed depending on the memory 
attributes of a memory access and the cache coherence protocol.

****
_A hardware cache coherence protocol may add additional cache states and may_
_cause additional cache block state transitions._
_The effects of a hardware cache coherence protocol on cache block states are_
_beyond the scope of this specification._
****

If two caches are in different domains, the copies in those caches are
_non-coherent_ with respect to each other.
In addition, two copies in different caches within the same domain are also
non-coherent with respect to each other if the memory attributes of a memory
access do not require both caches to be accessed.
Non-coherent copies may appear to have different data values, or the copies may
appear to have the same data values.
Software may enforce coherence on non-coherent copies using CMO instructions.

****
_The term_ coherent _implies a guarantee of coherence, while the term_
non-coherent _implies only the lack of such a guarantee, not a guarantee of_
_non-coherence._
****


****
Below are some properties/implications of the above definitions:

* Paths form a tree with the system agents as leaves and the PoC-memory as the 
  root; intermediate PoCs are nodes on the tree, while caches lie on the edges
  ** For example, a private L1 and L2 cache lie on the edge between a system 
    agent and the first PoC
* PoCs establish a hierarchy
  ** At each PoC, the set of agents whose memory accesses are ordered is the
    union of the sets defined by the previous PoCs
* Memory accesses on a path obey uniprocessor semantics
* Caches on the path from a domain PoC to the next PoC are effectively part of
  the domain
* Caches between PoCs are effectively part of the same domain
  ** The access order of caches between PoCs is implementation-defined (?)
* PoCs and domains 
* PoCs are accessed serially (?)
****



==== FIXME: PMA Behaviors

FIXME: Coherence and cacheability attributes...

Ignore cacheability to enable changes in attribute

Non-coherent implies that caches may not be accessed indirectly.


=== FIXME: Memory Ordering

==== Preserved Program Order

The preserved program order (abbreviated _PPO_ below) rules are defined by the 
RVWMO memory ordering model.
How the operations resulting from CMO instructions fit into these rules 
is described below.

For cache block management instructions, the resulting invalidate, clean, and 
flush operations behave as stores in the PPO rules subject to one additional 
overlapping address rule. Specifically, if _a_ precedes _b_ in program order, 
then _a_ will precede _b_ in the global memory order if:

* _a_ is an invalidate, clean, or flush, _b_ is a load, and _a_ and _b_ access 
  overlapping memory addresses

****
_The above rule ensures that a subsequent load operation in program order never 
appears in the global memory order before a preceding invalidate, clean, or 
flush operation to an overlapping address._
****

For cache block write instructions, the resulting write operations simply 
behave as stores in the PPO rules.

As cache block hint instructions do not modify architectural memory state, the 
resulting operations are _not_ ordered by the PPO rules.


==== Load Values

In addition, an invalidate operation changes the set of values that may be 
returned by a load. In particular, a third condition is added to the Load Value 
Axiom:

[start=3]
. If an invalidate precedes _i_ in program order and operates on a byte, and no 
store to that byte appears in program order or in the global memory order 
between the invalidate and _i_, the load value is _implementation-defined_

****
What does global memory order mean for software managed coherence:

* Can describe global to mean "global" for all agents and domains (single universe)
* Can describe global to mean "global" for some agents and domains (a multiverse)

The above definition is written using a multiverse definition for global memory
order. A single universe definition would constrain the result to orders that
could be produced by other agents. Maybe...?
****



== Traps

=== Illegal Instruction and Virtual Instruction Exceptions

Cache block management instructions and cache block write instructions may take 
an illegal instruction exception depending on the _current privilege mode_ and 
the state of the CMO control registers described in the <<_csrs>> section.
The current privilege mode refers to the privilege mode of the hart at the time 
the instruction is executed.

Cache block hint instructions do _not_ take illegal instruction exceptions.

Additionally, CMO instructions do _not_ take virtual instruction exceptions.

=== Page Fault and Guest-Page Fault Exceptions

During address translation, CMO instructions may take a page fault depending on 
the type of instruction, the _effective privilege mode_ (as determined by the 
`MPRV`, `MPV`, and `MPP` bits in `mstatus`) of the resulting access, and the 
permissions granted by the page table entry (PTE).
If two-stage address translation is enabled, CMO instructions may also take a 
guest-page fault.

Cache block management instructions require a valid translation (`V=1`) and 
either read (`R=1`) or execute (`X=1`) permission and, if applicable, user 
access (`U=1`) in the effective privilege mode.
If these conditions are _not_ met, the instruction takes a store/AMO page fault 
exception.
In addition, `CBO.INVAL` instructions may take a store/AMO page fault exception 
depending on the state of the CMO control registers described in the <<_csrs>> 
section and whether the access has been granted write permission by the PTE.

Cache block write instructions require a valid translation (`V=1`) and write 
(`W=1`) permission and, if applicable, user access (`U=1`) in the effective 
privilege mode.
If these conditions are _not_ met, the instruction takes a store/AMO page fault 
exception.

If G-stage address translation is enabled, the above instructions take a 
store/AMO guest-page fault if the G-stage PTE does _not_ allow the access.

Cache block hint instructions require a valid translation (`V=1`) and either 
read (`R=1`) or execute (`X=1`) permission and, if applicable, user access 
(`U=1`) in the effective privilege mode.
If these conditions are _not_ met, however, the instruction does _not_ take a 
page fault or guest-page fault exception and retires without accessing memory.

FIXME: PREFETCH.W interacts with LR/SC; doesn't require W=1

==== Effect of other `xstatus` bits

The `mstatus.MXR` bit (also `sstatus.MXR`) and the `vsstatus.MXR` bit do _not_ 
affect the execution of CMO instructions.

The `mstatus.SUM` bit (also `sstatus.SUM`) and the `vsstatus.SUM` bit do _not_ 
affect the execution of CMO instructions beyond modifying permissions for 
S/HS-mode and VS-mode accesses as specified by the privileged architecture.

=== Access Fault Exception

A CMO instruction may take an access fault exception, as detailed in the 
privileged architecture specification, that interrupts the address translation 
process.
Assuming the address translation process completes with a valid translation, a 
CMO instruction may also take an access fault exception depending on the type 
of instruction, the effective privilege mode of the resulting access, and the 
permissions granted by the physical memory protection (PMP) unit and the 
physical memory attributes (PMAs).

****
_For now, we assume two things about PMAs:_

. _PMAs are the same for all physical addresses in a cache block_
. _Memory that can be cached cannot be write-only_
****

Read (`R`), write (`W`), and execute (`X`) permissions are granted by the PMP 
and the PMAs.
Although the PMP may grant different permissions to different physical 
addresses in a cache block, the PMAs for a cache block _must_ be the same for 
_all_ physical addresses in the cache block and read permission _must_ be 
granted if write permission has been granted.
If these PMA constraints are _not_ met, the behavior of CMO instruction is 
UNSPECIFIED.

For the purposes of access fault determination, _joint permission_ is granted 
for a given physical address when the same access type is allowed by both the 
PMP and the PMAs for that physical address.
For example, joint read permission implies that both the PMP and PMAs allow 
a read access.
In addition, for a given cache block, _partial joint write permission_ implies 
that joint write permission has been granted to only _some_ of the physical 
addresses in the cache block, while _full joint write permission_ implies that 
joint write permission has been granted to _all_ physical addresses in the 
cache block.

Cache block management instructions require either joint read or joint execute 
permission for _all_ accessed physical addresses.
If this condition is _not_ met, the instruction takes a store/AMO access fault 
exception.
In addition, `CBO.INVAL` instructions may take a store/AMO access fault 
exception depending on the state of the CMO control registers described in the 
<<_csrs>> section and whether the access has been granted partial joint write 
permission by the PMP and PMAs.

Cache block write instructions require full joint write permission.
If this condition is _not_ met, the instruction takes a store/AMO access fault 
exception.

Cache block hint instructions require either joint read or joint execute 
permission for _all_ accessed physical addresses.
If this condition is _not_ met, however, the instruction does _not_ take an 
access fault exception and retires without accessing memory.

=== Address Misaligned Exception

CMO instructions do _not_ generate address misaligned exceptions.

=== Breakpoint Exception

CMO instructions may generate breakpoint exceptions (or may cause other debug 
actions) subject to the general trigger module behaviors specified in the debug 
architecture.
When `type=2` (i.e. `mcontrol`), the behavior of a trigger for load and store 
address matches is UNSPECIFIED for CMO instructions.
When `type=6` (i.e. `mcontrol6`), the behavior of a trigger for load and store 
address matches is based on the following classification of a CMO instruction:

* A cache block management instruction is both a load and a store
* A cache block write instruction is a store 
* It is _implementation-defined_ whether a cache block hint instruction is both 
  a load and a store or neither a load nor a store

Load and store data matches for all CMO instructions are UNSPECIFIED.

****
_An implementation may convert cache block hint instructions into NOPs prior to 
executing the instruction. Load and store matches are not applicable in such an 
implementation._

_For load and store address matches on a CMO effective address, software should 
program the trigger to match on NAPOT ranges, i.e. `mcontrol6.match=1`, and 
should program the NAPOT range to equal the cache block size._
****

== Formats

=== Instructions

For Zicbom and Zicboz:

 inst[6:0]   - 0b0001111 (MISC-MEM)
 inst[11:7]  - 0b00000 (rd - reserved)
 inst[14:12] - 0b010 (new funct3 encoding)
 inst[19:15] - rs1 (effective address)
 inst[24:20] - 0b00000 (rs2 - reserved)
 inst[31:25] - 0bxxxyyyy (funct7), where
    xxx:  0b000 (reserved for future modifiers)
    yyyy: 0b0000 - CBO.INVAL
          0b0001 - CBO.CLEAN
          0b0010 - CBO.FLUSH
          0b0100 - CBO.ZERO
          all others reserved

=== CSRs

*_FIXME_*: How is this extension disabled?

Four CSRs control execution of CMO instructions:

* `mcmocontrol`
* `scmocontrol`
* `hcmocontrol`
* `vscmocontrol`

****
_The `scmocontrol` and `vscmocontrol` registers are both required to
*distinguish CMO execution behavior when the effective privilege mode is U-mode
*or VU-mode, respectively. These registers are only present if the H-extension
*is implemented and  enabled._

We need a separate vscmocontrol register to differentiate between the effective
VU-mode behaviors and the effective U-mode behaviors in the scmocontrol when
MPRV=1. So even though the hypervisor could swap out scmocontrol before
returning to either VU/VS or U, M could arbitrarily perform effective VU or U
accesses without letting the hypervisor know.
****

Each `xcmocontrol` register has the following generic format:

.Generic Format for xcmocontrol CSRs
[cols="^1,^1,1a"]
[%autowidth]
|===
| Bits    | Name     | Description

| [0]     | `CBME`   | Cache Block Management instruction Enable

Determines the behavior of a cache block management instruction (i.e. 
`CBO.INVAL`, `CBO.CLEAN`, or `CBO.FLUSH`) when the instruction is executed in 
_privilege_mode_.

* `0`: The instruction takes an illegal instruction exception
* `1`: The instruction is executed

| [1]     | `CBWE`   | Cache Block Write instruction Enable

Determines the behavior of a cache block write instruction (i.e. `CBO.ZERO`) 
when the instruction is executed in _privilege_mode_.

* `0`: The instruction takes an illegal instruction exception
* `1`: The instruction is executed

| [7:2]   | _Rsvd_   | _Reserved_

| [8]     | `INVW0I` | `CBO.INVAL` access without write permission performs an 
Invalidate operation

Determines the operation performed by a `CBO.INVAL` instruction when the 
resulting access _has not been_ granted write permission in the effective 
privilege mode (_Wx_=`W0`) and when the instruction does _not_ raise an 
exception:

* `0`: The instruction performs a flush operation
* `1`: The instruction performs an invalidate operation

| [9]     | `INVW0E` | `CBO.INVAL` access without write permission Enable

Determines the behavior of a `CBO.INVAL` instruction when a 
_protection_mechanism_ is enabled and the resulting access _has not been_ 
granted write permission in the effective privilege mode (_Wx_=`W0`):

* `0`: The instruction takes an exception (page fault, guest-page fault, or 
  access fault depending on the CSR)
* `1`: The instruction performs an operation based on `INVW0I`

| [10]    | `INVW1I` | `CBO.INVAL` access with write permission performs an 
Invalidate operation

Determines the operation performed by a `CBO.INVAL` instruction when the 
resulting access _has been_ granted write permission in the effective privilege 
mode (_Wx_=`W1`) and when the instruction does _not_ raise an exception:

* `0`: The instruction performs a flush operation
* `1`: The instruction performs an invalidate operation

| [11]    | `INVW1E` | `CBO.INVAL` access with write permission Enable

Determines the behavior of a `CBO.INVAL` instruction when a 
_protection_mechanism_ is enabled and the resulting access _has been_ granted 
write permission in the effective privilege mode (_Wx_=`W1`):

* `0`: The instruction takes an exception (page fault, guest-page fault, or 
  access fault depending on the CSR)
* `1`: The instruction performs an operation based on `INVW1I`

| [x:12]  | _Rsvd_   | _Reserved_
|===

Each `xcmocontrol` register is WARL, where CSR reads return the behaviors 
supported by the implementation.

The following subsections detail how the `xcmocontrol` CSRs govern the 
execution of CMO instructions.

==== Determining Traps

===== Illegal Instruction Exceptions

The descriptions for the `CBME` and `CBWE` bits in the `xcmocontrol` registers 
include a _privilege_mode_ parameter that corresponds to the privilege modes 
controlled by a given CSR. Each CSR defines this parameter as follows:

* For `mcmocontrol`, _privilege_mode_ corresponds to S/HS-mode, U-mode, 
  VS-mode, and VU-mode
* For `scmocontrol`, _privilege_mode_ corresponds to U-mode
* For `hcmocontrol`, _privilege_mode_ corresponds to VS-mode and VU-mode
* For `vscmocontrol`, _privilege_mode_ corresponds to VU-mode

Depending on the _current privilege mode_, a cache block management instruction 
takes an illegal instruction exception based on the `CBME` bits:

* M-mode: +
  `FALSE` (cache block management instructions never take illegal instruction 
  exceptions)
* S/HS-mode: +
  `!mcmocontrol.CBME`
* U-mode: +
  `!mcmocontrol.CBME || !scmocontrol.CBME`
* VS-mode: +
  `!mcmocontrol.CBME || !hcmocontrol.CBME`
* VU-mode: +
  `!mcmocontrol.CBME || !hcmocontrol.CBME || !vscmocontrol.CBME`

Depending on the _current privilege mode_, a cache block write instruction 
takes an illegal instruction exception based on the `CBWE` bits:

* M-mode: +
  `FALSE` (cache block write instructions never take illegal instruction 
  exceptions)
* S/HS-mode: +
  `!mcmocontrol.CBWE`
* U-mode: +
  `!mcmocontrol.CBWE || !scmocontrol.CBWE`
* VS-mode: +
  `!mcmocontrol.CBWE || !hcmocontrol.CBWE`
* VU-mode: +
  `!mcmocontrol.CBWE || !hcmocontrol.CBWE || !vscmocontrol.CBWE`

Otherwise, the above instructions are executed in the _current privilege mode_.

===== Page Fault, Guest-Page Fault, and Access Fault Exceptions

The descriptions for the `INVWxE` and `INVWxI` bits in the `xcmocontrol` 
registers include a _protection_mechanism_ parameter that corresponds to the 
protection mechanism that determines write permission for an access and a 
_Wx_ parameter that represents whether write permission has been granted (`W1`) 
or not (`W0`).
Each CSR defines these as follows:

* For `mcmocontrol`, _protection_mechanism_ corresponds to the PMP and PMAs 
  and _Wx_ corresponds to whether partial joint write permission has been 
  granted by the PMP and PMAs
* For `scmocontrol`, _protection_mechanism_ corresponds to the `satp` page 
  table and _Wx_ corresponds to whether write permission has been granted by 
  the leaf PTE `W` bit
* For `hcmocontrol`, _protection_mechanism_ corresponds to the `hgatp` page 
  table and _Wx_ corresponds to whether write permission has been granted by 
  the leaf PTE `W` bit
* For `vscmocontrol`, _protection_mechanism_ corresponds to the `vsatp` page 
  table and _Wx_ corresponds to whether write permission has been granted by 
  the leaf PTE `W` bit

For each CSR, the resulting `INVWxE` value is determined by the designated 
_protection_mechanism_, which selects the `INVW0E` bit if _Wx_=`W0` or the 
`INVW1E` bit if _Wx_=`W1`.
Depending on the _effective privilege mode_, a `CBO.INVAL` instruction takes 
the following types of traps based on the `INVWxE` values:

* M-mode:
  **  _N/A_ (`CBO.INVAL` never faults due to the CMO control registers)
* S/HS-mode:
  ** Access fault: +
    `!(mcmocontrol.INVWxE)`
* U-mode:
  ** Page fault: +
    `!(scmocontrol.INVWxE || satp.MODE==Bare)`
  ** Access fault: +
    `(scmocontrol.INVWxE || satp.MODE==Bare) &&` +
    `!(mcmocontrol.INVWxE)`
* VS-mode:
  ** Guest-page fault: +
    `!(hcmocontrol.INVWxE || hgatp.MODE==Bare)`
  ** Access fault: +
    `(hcmocontrol.INVWxE || hgatp.MODE==Bare) &&` +
    `!(mcmocontrol.INVWxE)`
* VU-mode:
  ** Page fault: +
    `!(vscmocontrol.INVWxE || vsatp.MODE==Bare)`
  ** Guest-page fault: +
    `(vscmocontrol.INVWxE || vsatp.MODE==Bare) &&` +
    `!(hcmocontrol.INVWxE || hgatp.MODE==Bare)`
  ** Access fault: +
    `(vscmocontrol.INVWxE || vsatp.MODE==Bare) &&` +
    `(hcmocontrol.INVWxE || hgatp.MODE==Bare) &&` +
    `!(mcmocontrol.INVWxE)`

****
_The above exception priorities reflect the architected exception priorities in 
the privileged architecture specification._
****

For each CSR, the resulting `INVWxI` value is determined by the designated 
_protection_mechanism_, which selects the `INVW0I` bit if _Wx_=`W0` or the 
`INVW1I` bit if _Wx_=`W1`, if that protection mechanism is enabled.
If the protection mechanism is disabled, the `INVWxI` value is the logical AND 
of the `INVW0I` bit and the `INVW1I` bit, i.e. both bits _must_ be set to 
perform an invalidate operation.
Assuming that no exception arises and depending on the 
_effective privilege mode_, a `CBO.INVAL` instruction performs the following 
operations based on the `INVWxI` values:

* M-mode:
  ** Flush: +
  `FALSE` (`CBO.INVAL` never performs a flush operation)
  ** Invalidate: +
  `TRUE` (`CBO.INVAL` always performs an invalidate operation)
* S-mode:
  ** Flush: +
    `!(mcmocontrol.INVWxI)`
  ** Invalidate: +
    `(mcmocontrol.INVWxI)`
* U-mode:
  ** Flush: +
    `!(scmocontrol.INVWxI && mcmocontrol.INVWxI)`
  ** Invalidate: +
    `(scmocontrol.INVWxI && mcmocontrol.INVWxI)`
* VS-mode:
  ** Flush: +
    `!(hcmocontrol.INVWxI && mcmocontrol.INVWxI)`
  ** Invalidate: +
    `(hcmocontrol.INVWxI && mcmocontrol.INVWxI)`
* VU-mode:
  ** Flush: +
    `!(vscmocontrol.INVWxI && hcmocontrol.INVWxI && mcmocontrol.INVWxI)`
  ** Invalidate: +
    `(vscmocontrol.INVWxI && hcmocontrol.INVWxI && mcmocontrol.INVWxI)`

****
_Until a modified cache block has updated memory, a `CBO.INVAL` instruction may
expose stale data values in memory if the CSRs are programmed to perform an 
invalidate operation._
_This behavior may result in a security hole if lower privileged level software 
performs an invalidate operation and accesses sensitive information in memory._
_To avoid such holes, higher privileged level software must perform either a 
clean or flush operation on the cache block before permitting lower privileged 
level software to perform an invalidate operation on the block._

_Alternatively, higher privileged level software may program the CSRs so that 
`CBO.INVAL` either traps or performs a flush operation in a lower privileged 
level._
_The W0 and W1 bits allow higher privileged software finer-grained control of 
the behavior of `CBO.INVAL` in lower privilege levels based on whether write 
permission has been granted to that level by a particular protection 
mechanism._
****

== Instructions

=== Cache Block Management Instructions

Cache block management instructions operate on the cache blocks containing the 
effective address specified in _rs1_.
These instructions also specify a _PoC_ that, along with the coherence PMA, 
determines the set of caches on which the operation is performed.
In particular, the set of caches consists of one of the following:

* If the coherence PMA indicates that hardware enforces coherence on the 
  physical address, all the caches accessed by the hart directly and indirectly 
  in the coherence domains on the path from the hart to the _PoC_
* If the coherence PMA indicates that hardware does _not_ enforce coherence on 
  the physical address, only the caches accessed by the hart directly on the 
  path from the hart to the _PoC_

==== `CBO.INVAL`

A `CBO.INVAL` instruction performs an _invalidate_ operation or a _flush_ 
operation, depending on the state of the CMO CSRs, on the set of caches 
determined by the _PoC_ and the coherence PMA.

==== `CBO.CLEAN`

A `CBO.CLEAN` instruction performs a _clean_ operation on the set of caches 
determined by the _PoC_ and the coherence PMA.

==== `CBO.FLUSH`

A `CBO.FLUSH` instruction performs a _flush_ operation on the set of caches 
determined by the _PoC_ and the coherence PMA.

=== Cache Block Write Instruction

Cache block write instructions operate on the cache blocks containing the 
effective address specified in _rs1_.
These instructions also specify a _level_, which is a hint to the hardware to 
allocate the cache block in a designated cache.
_level_ is specified as follows:

* `default` -- an _implementation-defined_ level, which may be a function of
  physical addresses, dynamic allocation policies, or any other characteristic
* `L1` -- the first cache logically accessed by a hart on the path to memory
* `L2` -- the second cache logically accessed by a hart on the path to memory
* `L3` -- the third cache logically accessed by a hart on the path to memory

An implementation may ignore _level_ and assume _level_ is `default` for all 
cache block write instructions.

****
_To a certain degree, level is implementation-defined for all systems; however, 
`L1`, `L2`, and `L3` are intended to communicate their common, informal 
meaning._
****

==== `CBO.ZERO`

A `CBO.ZERO` instruction performs a series of byte writes whose data value 
equals zero to all the bytes in a cache block.
An implementation may write any number of bytes in the cache block atomically.
The instruction may allocate, but is _not_ guaranteed to allocate, the cache 
block in the cache specified by _level_.

=== Cache Block Hint Instructions

Cache block hint instructions operate on the cache blocks containing the 
effective address specified in _rs1_.
These instructions also specify a _level_, which is a hint to the hardware to 
allocate the cache block in a designated cache.
_level_ is specified as follows:

* `default` -- an _implementation-defined_ level, which may be a function of
  physical addresses, dynamic allocation policies, or any other characteristic
* `L1` -- the first cache logically accessed by a hart on the path to memory
* `L2` -- the second cache logically accessed by a hart on the path to memory
* `L3` -- the third cache logically accessed by a hart on the path to memory

An implementation may ignore _level_ and assume _level_ is `default` for all 
cache block hint instructions.

****
_To a certain degree, level is implementation-defined for all systems; however, 
`L1`, `L2`, and `L3` are intended to communicate their common, informal 
meaning._
****

==== `PREFETCH.R`

A `PREFETCH.R` instruction indicates to the cache at the specified _level_ that 
a subsequent read operation is likely to be performed on the cache block at the
specified effective address in the near future.

An implementation typically allocates the cache block in the cache at the 
specified _level_ in a state that allows read access; however, the instruction 
is _not_ guaranteed to allocate the cache block in that cache.

==== `PREFETCH.W`

A `PREFETCH.W` instruction indicates to the cache at the specified _level_ that 
a subsequent write operation is likely to be performed on the cache block at 
the specified effective address in the near future.

An implementation typically allocates the cache block in the cache at the 
specified _level_ in a state that allows write access; however, the instruction 
is _not_ guaranteed to allocate the cache block in that cache.

A PREFETCH.W instruction may interfere with the eventual success guarantee of 
store-conditional instructions.

==== `PREFETCH.I`

A `PREFETCH.I` instruction indicates to the cache at the specified _level_ that 
a subsequent instruction fetch operation is likely to be performed on the 
cache block at the specified effective address in the near future.

An implementation typically allocates the cache block in the cache at the 
specified _level_ in a state that allows instruction fetch access; however, the 
instruction is _not_ guaranteed to allocate the cache block in that cache.

Instruction fetch operations may access caches different from those accessed by 
read and write operations.
It is _implementation-defined_ whether the cache at the specified _level_ in a 
`PREFETCH.I` instruction is the same cache at the specified _level_ in a 
`PREFETCH.R` or `PREFETCH.W` instruction.

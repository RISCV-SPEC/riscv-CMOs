== Introduction

The Zicmobase extension adds a base set of _cache management operation_ (or 
_CMO_) instructions and CSRs to the RISC-V architecture.
The base extension includes several classes of instructions that operate on 
cache blocks:

* A set of cache block management instructions, i.e. `CBO.INVAL`, `CBO.CLEAN`, 
  and `CBO.FLUSH`
* A cache block write instruction, i.e. `CBO.ZERO`
* A set of cache block hint instructions, i.e. `PREFETCH.R`, `PREFETCH.W`, 
  `PREFETCH.I`, and `DEMOTE`
* A cache block size discovery instruction, i.e. `CBO.SIZE` (TBD)

The execution of these instructions in various privilege modes is controlled by 
a set of CSRs.
In addition, this specification introduces architectural abstractions for 
caches and system topologies to support portable software across various system 
designs.

=== Goals

* Define instructions that operate on an architectural abstraction of caches 
  and system topology
* Specify the interactions of CMOs with the RVWMO memory ordering model
* Support various software use-cases such as software-managed cache coherence
  and non-coherent I/O
* Allow execution of CMOs in lower privilege modes, including U-mode

=== Non-Goals

The following goals are intentionally deferred to a later specification:

* Cache management operations on microarchitectural characteristics, e.g. 
  set/way operations or whole cache operations
* Specifying the behavior of cache management operations on different cache 
  block sizes
* Performance has _not_ been a primary goal for this version of the 
  specification (though the specification is mindful not to hinder performance)

== Overview

In general, a CMO instruction initiates an operation on a set of caches based 
on instruction type, CSR state, physical memory attributes, and other 
architectural state.
A CMO instruction specifies an effective address, which may be translated by 
various translation mechanisms into a physical address.
A hart may then perform a subsequent memory access with that physical address 
in order to operate on various caches throughout a system.

=== Memory and Caches in RISC-V

As specified in the RISC-V base and privileged architectures, memory is 
organized as an array of bytes, with a given physical address identifying a 
particular memory location.
Each memory location is further associated with a main memory region, an I/O 
device region, or a vacant region.
In this extension, a _memory agent_ services memory accesses to a set of memory 
locations that comprise a memory region (of any type), while a _system agent_ 
performs memory accesses to memory locations and may be a hart or an I/O device 
(or _device_ for short).

****
_A particular I/O device may be a memory agent, a system agent, or both._
****

Caches in RISC-V reduce average memory latency by buffering copies of data from 
frequently accessed memory locations close to system agents.
Specifically, a cache buffers copies of _cache blocks_, each of which consists 
of a contiguous, non-overlapping, naturally aligned power-of-two (NAPOT) set of 
bytes and corresponds to a similarly NAPOT set of memory locations and 
associated physical addresses.
A system may make multiple copies of a given cache block, and these copies may 
be transferred to and from various caches and memory.
The underlying memory locations for a cache block form the _backing storage_ 
for the block, and the organization of a cache and the size of a cache block 
are _implementation-defined_.

RISC-V defines three types of caches: A _private cache_ is accessed by a single 
system agent, while a _shared cache_ is accessed by more than one system agent.
In addition, a _memory cache_ is localized to memory agent and is effectively 
"invisible" to the system agents that access a given memory location.
(In other words, a memory cache may serve as a proxy for the actual physical 
memory location.)
The base set of cache management operations operates on private and shared 
caches only and is _not_ guaranteed to operate on memory caches.

*_FIXME:_* types of cache blocks?

==== Cache Block States

Relative to a given cache, a cache block may be in one of three states:

* _Invalid_ -- the cache block is _not_ present in the cache
* _Unmodified_ -- the cache block is present in the cache and _this_ copy has 
  _not_ been written by a system agent
* _Modified_ -- the cache block is present in the cache and _this_ copy has been 
  written by a system agent

All caches differentiate between invalid and unmodified cache blocks, and a
cache may or may not track modified cache blocks depending on 
_implementation-defined_ write policies, e.g. write-back or write-through,
respectively.
A cache, therefore, may implement only two states (invalid and unmodified) or 
all three states (invalid, unmodified, and modified).
Additionally, a cache block in either the unmodified or modified state is 
considered to be _valid_.

In addition, based on _implementation-defined_ system-wide cache policies and 
mechanisms, an unmodified cache block may _not_ be consistent with memory, and 
a modified copy may be present in another cache at the same time.
Furthermore, the state of the cache block may also be communicated when the 
block is transferred to or from the cache.
These policies and mechanisms are typically defined by a cache coherence 
protocol (see the <<_system_topology>> section) and are beyond the scope of 
this specification.

A transition from invalid to valid occurs when a cache allocates a cache block, 
resulting in a transfer of the block to the cache from another cache or memory 
(performing a _memory read_ in the latter case).
To the extent allowed by the base and privileged architectures, a cache may 
allocate a cache block for any physical address at any time for any reason.
The cache block is allocated in either the unmodified or modified state 
depending on whether the cache tracks modified cache blocks and whether an 
unmodified or modified cache block is transferred to the cache.

A transition from valid to invalid occurs when a cache deallocates the cache 
block, potentially resulting in a transfer of the block from the cache to 
another cache or memory (performing a _memory write_ in the latter case).
A cache may deallocate a cache block at any time for any reason.
If the cache block is unmodified, the cache may transfer the cache block to 
another cache but _must not_ transfer the cache block to memory to avoid 
overwriting memory with potentially stale data.
(The behavior of CMO instructions becomes UNSPECIFIED if a cache transfers an 
unmodified cache block to memory.)
If the cache block is modified, the cache _must_ transfer the modified block to 
another cache or memory.

Finally, if the cache tracks modified cache blocks, a transition from 
unmodified to modified occurs whenever a system agent executes an instruction, 
e.g. a store instruction, or performs an operation, e.g. a page table entry 
write, that writes to a cache block that has been transferred to the cache.
To cause the transition, the instruction or operation only needs to be 
classified as a data write that _may_ change the data values in the cache 
block; the data write is _not_ required to change the data values.
If the cache does _not_ track modified cache blocks, the data write _must_ be 
propagated either to another cache that does track modified cache blocks or to 
memory.
In such a cache, the data write _must_ update the data values of the cache 
block, or the cache block _must_ transition to invalid.

==== CMO Effects on Caches

CMO instructions may also affect the state of a cache block.
A cache block management instruction performs one of the following operations, 
which may change the state of a cache block and may result in a transfer of 
data from the cache:

* An _invalidate_ operation _must_ change the state of a valid cache block 
  to invalid; otherwise, no state change occurs.
  The operation may transfer the cache block if its state was valid before the 
  operation; however, the transfer of the cache block is _not_ required.
* A _clean_ operation _must_ change the state of a modified cache block to 
  unmodified, although the operation may change the state of a valid cache 
  block to invalid; otherwise, no state change occurs.
  The operation _must_ transfer the cache block if its state was modified 
  before the operation and may transfer the cache block if its state was 
  unmodified before the operation.
* A _flush_ operation _must_ change the state of a valid cache block to 
  invalid; otherwise, no state change occurs.
  The operation _must_ transfer the cache block if its state was modified 
  before the operation and may transfer the cache block if its state was 
  unmodified before the operation.

A cache block write instruction effectively performs a series of byte atomic 
data write operations, similar to a series of store byte instructions.
An implementation may or may not update the entire cache block atomically.

Finally, a cache block hint instruction may perform an _implementation-defined_ 
operation or no operation, the latter of which does not affect the state of the 
cache.

=== System Topology

A memory access from a CMO instruction proceeds along _memory access path_ (or 
_path_ for short) from a given system agent toward a given memory location.
A path is determined primarily by the following characteristics:

* The physical address of the memory access
* The memory attributes associated with the memory access

The physical address identifies the memory location being accessed and is a 
function of the effective address specified by a CMO instruction and any 
enabled translation mechanisms.
In addition, the memory attributes for a memory access may be specified by 
either architectural or _implementation-defined_ mechanisms.
Other factors, such as type of operation, may also influence the path.

****
_The memory attributes that typically affect a path are related to cacheability_
_and coherence; however, other memory attributes may affect a path._

_From the same system agent, paths for memory accesses with the same memory_
_attributes to different memory locations may be different._
_Likewise, paths for memory accesses with different memory attributes to the_
_same memory location may be different._
****

Paths from different system agents to the same memory location converge at a 
_point of convergence_ (or _PoC_), and from a given PoC, the paths that have 
converged do not diverge.
In addition, the memory accesses on those paths are ordered, and remain 
ordered, with respect to each other from a PoC until the memory accesses can be 
completed.
A PoC is _not_ required to order memory accesses to different memory locations.
Once an order has been established, those memory accesses are considered to be 
_access ordered_ and cannot be reordered within the system.

****
_This ordering definition is necessary to implement cache coherence protocols_
_and forms the basis for the memory ordering model below._
_Effectively, a PoC establishes a coherence order for a given memory location_
_with respect to a given set of agents._
****

For every memory location in a system, the _point of convergence of memory_, or 
_PoC-memory_, is the PoC where all paths for a given memory location converge, 
independent of all other characteristics that define a path.
At the PoC-memory, all accesses to a memory location have been access ordered, 
and the CMO instructions defined in this extension are guaranteed to operate on 
a path up to the PoC-memory.

*_FIXME:_* Define other standard PoCs?

****
_This extension does not prohibit system agents from bypassing the PoC-memory_
_to access a memory location, nor does the extension prohibit memory caches_
_beyond the PoC-memory._
_However, in such a system, software cannot expect the currently defined cache_
_operations to have the desired effects with respect to those system agents or_
_caches._

_Additional system topology beyond the PoC-memory may be specified in future_
_extensions._
_For example, additional points of convergence may be defined to manage memory_
_caches, or various points of persistence may be defined to support different_
_classes of storage._
****

A system may define additional custom PoCs before the PoC-memory, and when such 
a PoC is specified in a CMO instruction, the instruction _must_ operate on a 
given path up to the custom PoC and may operate on the path up to the 
PoC-memory.
A CMO instruction is _not_ required, however, to operate on the path beyond a 
custom PoC.

****
_The above definition allows an implementation to perform all operations to_
_custom PoCs before the PoC-memory as if such operations were performed to the_
_PoC-memory._
****

While traversing a given path, a memory access from a CMO instruction operates
on the caches up to the specified PoC.
Between a system agent and the first PoC on the path, the memory access
operates on private caches, and between subsequent PoCs, the memory access
operates on shared caches.
There is no requirement, however, for any caches to be present either between a
system agent and the first PoC or between subsequent PoCs.
Caches on the path are accessed _directly_ by the memory access.
Additional caches on the paths that converge at a given PoC may be accessed
_indirectly_ depending on the memory attributes associated with a memory access
and any _implementation-defined_ cache coherence mechanisms.

Systems may implement hardware cache coherence mechanisms to ensure that the 
copies in a set of caches remain _coherent_ with respect to each other, i.e. 
the copies in the set of caches appear to have the same data values, regardless 
of which cache in the set is accessed.
The set of caches on which hardware can maintain this property corresponds to a 
_hardware coherence domain_ (or _domain_ for short), which may consist of any 
number of caches, including an individual cache.
Only a subset of the caches in a domain may be accessed depending on the memory 
attributes of a memory access and the cache coherence protocol.

****
_A hardware cache coherence protocol may add additional cache states and may_
_cause additional cache block state transitions._
_The effects of a hardware cache coherence protocol on cache block states are_
_beyond the scope of this specification._
****

If two caches are in different domains, the copies in those caches are
_non-coherent_ with respect to each other.
In addition, two copies in different caches within the same domain are also
non-coherent with respect to each other if the memory attributes of a memory
access do not require both caches to be accessed.
Non-coherent copies may appear to have different data values, or the copies may
appear to have the same data values.
Software may enforce coherence on non-coherent copies using CMO instructions.

****
_The term_ coherent _implies a guarantee of coherence, while the term_
non-coherent _implies only the lack of such a guarantee, not a guarantee of_
_non-coherence._
****


****
Below are some properties/implications of the above definitions:

* Paths form a tree with the system agents as leaves and the PoC-memory as the 
  root; intermediate PoCs are nodes on the tree, while caches lie on the edges
  ** For example, a private L1 and L2 cache lie on the edge between a system 
    agent and the first PoC
* PoCs establish a hierarchy
  ** At each PoC, the set of agents whose memory accesses are ordered is the
    union of the sets defined by the previous PoCs
* Memory accesses on a path obey uniprocessor semantics
* Caches on the path from a domain PoC to the next PoC are effectively part of
  the domain
* Caches between PoCs are effectively part of the same domain
  ** The access order of caches between PoCs is implementation-defined (?)
* PoCs and domains 
* PoCs are accessed serially (?)
****

.Ignore Me
****
Random stuff being worked on:

_PoCs-domain_

memory accesses due to loads and stores can be ordered anywhere in a domain, but the
ultimate point of ordering for the domain is the PoC-domain.
memory accesses due to CMOs operate to a PoC-domain and guarantee the whole domain
has been operated on

Domains correspond to particular PoCs.
A _PoC-domain_ (working title) is defined to be the PoC at which all paths that
pass through any cache in the domain before the PoC converge.
Systems may have any number of PoCs-domain visible to software via memory 
attributes or as custom PoCs.
In addition, a domain may be asymmetric with respect to the paths that converge
at a PoC-domain.
Specifically, a memory access on one path may indirectly access the caches on a
second path, while a memory access on the second path may _not_ indirectly
access the caches on the first.


SW view: POCs define sets of agents that communicate coherently without SW help


*_FIXME:_* Domains can be mapped outward; within the frontier, outside the frontier

Is there such a thing as a PoC-hart that represents uniprocessor ordering?
That makes the tree definition a bit more easy since a leaf becomes a PoC (but
nothing is really converging, unless you consider loads and stores as separate 
things converging)

Structural definition: relative to system agent. L1 is the "first" cache accessed, etc.
****


==== FIXME: PMA Behaviors

FIXME: Coherence and cacheability attributes...

Ignore cacheability to enable changes in attribute

Non-coherent implies that caches may not be accessed indirectly.


=== FIXME: Memory Ordering

==== Preserved Program Order

The preserved program order (abbreviated _PPO_ below) rules are defined by the 
RVWMO memory ordering model.
How the operations resulting from CMO instructions fit into these rules 
is described below.

For cache block management instructions, the resulting invalidate, clean, and 
flush operations behave as stores in the PPO rules subject to one additional 
overlapping address rule. Specifically, if _a_ precedes _b_ in program order, 
then _a_ will precede _b_ in the global memory order if:

* _a_ is an invalidate, clean, or flush, _b_ is a load, and _a_ and _b_ access 
  overlapping memory addresses

****
_The above rule ensures that a subsequent load operation in program order never 
appears in the global memory order before a preceding invalidate, clean, or 
flush operation to an overlapping address._
****

For cache block write instructions, the resulting write operations simply 
behave as stores in the PPO rules.

As cache block hint instructions do not modify architectural memory state, the 
resulting operations are _not_ ordered by the PPO rules.


==== Load Values

In addition, an invalidate operation changes the set of values that may be 
returned by a load. In particular, a third condition is added to the Load Value 
Axiom:

[start=3]
. If an invalidate precedes _i_ in program order and operates on a byte, and no 
store to that byte appears in program order or in the global memory order 
between the invalidate and _i_, the load value is _implementation-defined_

****
What does global memory order mean for software managed coherence:

* Can describe global to mean "global" for all agents and domains (single universe)
* Can describe global to mean "global" for some agents and domains (a multiverse)

The above definition is written using a multiverse definition for global memory
order. A single universe definition would constrain the result to orders that
could be produced by other agents. Maybe...?
****

==== Ordering Events

Ordering event for CMO: access ordered at explicit PoC

Ordering event for load: access ordered in the implicit domain

Ordering event for store: access ordered in the implicit domain

PPO specifies the order of the ordering events

=== FIXME: Discovery

FIXME: HW vs. SW

For now, fixed size across all harts and devices that share a domain

=== Traps

==== Illegal Instruction and Virtual Instruction Exceptions

Cache block management instructions and cache block write instructions may take 
an illegal instruction exception depending on the _current privilege mode_ and 
the state of the CMO control registers described in the <<_csrs>> section.
The current privilege mode refers to the privilege mode of the hart at the time 
the instruction is executed.

Cache block hint instructions do _not_ take illegal instruction exceptions.

Additionally, CMO instructions do _not_ take virtual instruction exceptions.

==== Page Fault and Guest-Page Fault Exceptions

During address translation, CMO instructions may take a page fault depending on 
the type of instruction, the _effective privilege mode_ (as determined by the 
`MPRV`, `MPV`, and `MPP` bits in `mstatus`) of the resulting access, and the 
permissions granted by the page table entry (PTE).
If two-stage address translation is enabled, CMO instructions may also take a 
guest-page fault.

Cache block management instructions require a valid translation (`V=1`) and 
either read (`R=1`) or execute (`X=1`) permission and, if applicable, user 
access (`U=1`) in the effective privilege mode.
If these conditions are _not_ met, the instruction takes a store/AMO page fault 
exception.
In addition, `CBO.INVAL` instructions may take a store/AMO page fault exception 
depending on the state of the CMO control registers described in the <<_csrs>> 
section and whether the access has been granted write permission by the PTE.

Cache block write instructions require a valid translation (`V=1`) and write 
(`W=1`) permission and, if applicable, user access (`U=1`) in the effective 
privilege mode.
If these conditions are _not_ met, the instruction takes a store/AMO page fault 
exception.

If G-stage address translation is enabled, the above instructions take a 
store/AMO guest-page fault if the G-stage PTE does _not_ allow the access.

Cache block hint instructions require a valid translation (`V=1`) and either 
read (`R=1`) or execute (`X=1`) permission and, if applicable, user access 
(`U=1`) in the effective privilege mode.
If these conditions are _not_ met, however, the instruction does _not_ take a 
page fault or guest-page fault exception and retires without accessing memory.

FIXME: PREFETCH.W interacts with LR/SC; doesn't require W=1

===== Effect of other `xstatus` bits

The `mstatus.MXR` bit (also `sstatus.MXR`) and the `vsstatus.MXR` bit do _not_ 
affect the execution of CMO instructions.

The `mstatus.SUM` bit (also `sstatus.SUM`) and the `vsstatus.SUM` bit do _not_ 
affect the execution of CMO instructions beyond modifying permissions for 
S/HS-mode and VS-mode accesses as specified by the privileged architecture.

==== Access Fault Exception

A CMO instruction may take an access fault exception, as detailed in the 
privileged architecture specification, that interrupts the address translation 
process.
Assuming the address translation process completes with a valid translation, a 
CMO instruction may also take an access fault exception depending on the type 
of instruction, the effective privilege mode of the resulting access, and the 
permissions granted by the physical memory protection (PMP) unit and the 
physical memory attributes (PMAs).

****
_For now, we assume two things about PMAs:_

. _PMAs are the same for all physical addresses in a cache block_
. _Memory that can be cached cannot be write-only_
****

Read (`R`), write (`W`), and execute (`X`) permissions are granted by the PMP 
and the PMAs.
Although the PMP may grant different permissions to different physical 
addresses in a cache block, the PMAs for a cache block _must_ be the same for 
_all_ physical addresses in the cache block and read permission _must_ be 
granted if write permission has been granted.
If these PMA constraints are _not_ met, the behavior of CMO instruction is 
UNSPECIFIED.

For the purposes of access fault determination, _joint permission_ is granted 
for a given physical address when the same access type is allowed by both the 
PMP and the PMAs for that physical address.
For example, joint read permission implies that both the PMP and PMAs allow 
a read access.
In addition, for a given cache block, _partial joint write permission_ implies 
that joint write permission has been granted to only _some_ of the physical 
addresses in the cache block, while _full joint write permission_ implies that 
joint write permission has been granted to _all_ physical addresses in the 
cache block.

Cache block management instructions require either joint read or joint execute 
permission for _all_ accessed physical addresses.
If this condition is _not_ met, the instruction takes a store/AMO access fault 
exception.
In addition, `CBO.INVAL` instructions may take a store/AMO access fault 
exception depending on the state of the CMO control registers described in the 
<<_csrs>> section and whether the access has been granted partial joint write 
permission by the PMP and PMAs.

Cache block write instructions require full joint write permission.
If this condition is _not_ met, the instruction takes a store/AMO access fault 
exception.

Cache block hint instructions require either joint read or joint execute 
permission for _all_ accessed physical addresses.
If this condition is _not_ met, however, the instruction does _not_ take an 
access fault exception and retires without accessing memory.

==== Address Misaligned Exception

CMO instructions do _not_ generate address misaligned exceptions.

==== Breakpoint Exception

CMO instructions may generate breakpoint exceptions (or may cause other debug 
actions) subject to the general trigger module behaviors specified in the debug 
architecture.
When `type=2` (i.e. `mcontrol`), the behavior of a trigger for load and store 
address matches is UNSPECIFIED for CMO instructions.
When `type=6` (i.e. `mcontrol6`), the behavior of a trigger for load and store 
address matches is based on the following classification of a CMO instruction:

* A cache block management instruction is both a load and a store
* A cache block write instruction is a store 
* It is _implementation-defined_ whether a cache block hint instruction is both 
  a load and a store or neither a load nor a store

Load and store data matches for all CMO instructions are UNSPECIFIED.

****
_An implementation may convert cache block hint instructions into NOPs prior to 
executing the instruction. Load and store matches are not applicable in such an 
implementation._

_For load and store address matches on a CMO effective address, software should 
program the trigger to match on NAPOT ranges, i.e. `mcontrol6.match=1`, and 
should program the NAPOT range to equal the cache block size._
****
